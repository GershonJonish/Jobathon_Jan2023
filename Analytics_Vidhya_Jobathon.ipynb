{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b1a846f0",
   "metadata": {},
   "source": [
    "# Importing Libraries and Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "393b0062",
   "metadata": {
    "id": "393b0062"
   },
   "outputs": [],
   "source": [
    "# Import the libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sweetviz as sv\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "from lazypredict.Supervised import LazyRegressor\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from flaml import AutoML\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "nDZJ0CfJra3U",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nDZJ0CfJra3U",
    "outputId": "fc615c59-dd06-4dd8-b9dd-e9c86031352e"
   },
   "outputs": [],
   "source": [
    "#from google.colab import drive\n",
    "#drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "DxbgSyA7rpjH",
   "metadata": {
    "id": "DxbgSyA7rpjH"
   },
   "outputs": [],
   "source": [
    "# Load the data\n",
    "train = pd.read_csv('train_BRCpofr.csv')\n",
    "test = pd.read_csv('test_koRSKBP.csv')\n",
    "ss = pd.read_csv('sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3156cc90",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "3156cc90",
    "outputId": "968eae5d-84b0-4af5-b4d1-e3035071f2ef"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>gender</th>\n",
       "      <th>area</th>\n",
       "      <th>qualification</th>\n",
       "      <th>income</th>\n",
       "      <th>marital_status</th>\n",
       "      <th>vintage</th>\n",
       "      <th>claim_amount</th>\n",
       "      <th>num_policies</th>\n",
       "      <th>policy</th>\n",
       "      <th>type_of_policy</th>\n",
       "      <th>cltv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Male</td>\n",
       "      <td>Urban</td>\n",
       "      <td>Bachelor</td>\n",
       "      <td>5L-10L</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5790</td>\n",
       "      <td>More than 1</td>\n",
       "      <td>A</td>\n",
       "      <td>Platinum</td>\n",
       "      <td>64308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Male</td>\n",
       "      <td>Rural</td>\n",
       "      <td>High School</td>\n",
       "      <td>5L-10L</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>5080</td>\n",
       "      <td>More than 1</td>\n",
       "      <td>A</td>\n",
       "      <td>Platinum</td>\n",
       "      <td>515400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Male</td>\n",
       "      <td>Urban</td>\n",
       "      <td>Bachelor</td>\n",
       "      <td>5L-10L</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>2599</td>\n",
       "      <td>More than 1</td>\n",
       "      <td>A</td>\n",
       "      <td>Platinum</td>\n",
       "      <td>64212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Female</td>\n",
       "      <td>Rural</td>\n",
       "      <td>High School</td>\n",
       "      <td>5L-10L</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>More than 1</td>\n",
       "      <td>A</td>\n",
       "      <td>Platinum</td>\n",
       "      <td>97920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Male</td>\n",
       "      <td>Urban</td>\n",
       "      <td>High School</td>\n",
       "      <td>More than 10L</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>3508</td>\n",
       "      <td>More than 1</td>\n",
       "      <td>A</td>\n",
       "      <td>Gold</td>\n",
       "      <td>59736</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  gender   area qualification         income  marital_status  vintage  \\\n",
       "0   1    Male  Urban      Bachelor         5L-10L               1        5   \n",
       "1   2    Male  Rural   High School         5L-10L               0        8   \n",
       "2   3    Male  Urban      Bachelor         5L-10L               1        8   \n",
       "3   4  Female  Rural   High School         5L-10L               0        7   \n",
       "4   5    Male  Urban   High School  More than 10L               1        6   \n",
       "\n",
       "   claim_amount num_policies policy type_of_policy    cltv  \n",
       "0          5790  More than 1      A       Platinum   64308  \n",
       "1          5080  More than 1      A       Platinum  515400  \n",
       "2          2599  More than 1      A       Platinum   64212  \n",
       "3             0  More than 1      A       Platinum   97920  \n",
       "4          3508  More than 1      A           Gold   59736  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_columns', 50)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "674a6f8e",
   "metadata": {
    "id": "674a6f8e"
   },
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0fa8a889",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(89392, 12)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1634ba54",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1634ba54",
    "outputId": "7d7b0ee9-d50d-4f09-bcaf-d0839463d4ee"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 89392 entries, 0 to 89391\n",
      "Data columns (total 12 columns):\n",
      " #   Column          Non-Null Count  Dtype \n",
      "---  ------          --------------  ----- \n",
      " 0   id              89392 non-null  int64 \n",
      " 1   gender          89392 non-null  object\n",
      " 2   area            89392 non-null  object\n",
      " 3   qualification   89392 non-null  object\n",
      " 4   income          89392 non-null  object\n",
      " 5   marital_status  89392 non-null  int64 \n",
      " 6   vintage         89392 non-null  int64 \n",
      " 7   claim_amount    89392 non-null  int64 \n",
      " 8   num_policies    89392 non-null  object\n",
      " 9   policy          89392 non-null  object\n",
      " 10  type_of_policy  89392 non-null  object\n",
      " 11  cltv            89392 non-null  int64 \n",
      "dtypes: int64(5), object(7)\n",
      "memory usage: 8.2+ MB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4a320295",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                0\n",
       "gender            0\n",
       "area              0\n",
       "qualification     0\n",
       "income            0\n",
       "marital_status    0\n",
       "vintage           0\n",
       "claim_amount      0\n",
       "num_policies      0\n",
       "policy            0\n",
       "type_of_policy    0\n",
       "cltv              0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d3608093",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>marital_status</th>\n",
       "      <th>vintage</th>\n",
       "      <th>claim_amount</th>\n",
       "      <th>cltv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>89392.00</td>\n",
       "      <td>89392.00</td>\n",
       "      <td>89392.00</td>\n",
       "      <td>89392.00</td>\n",
       "      <td>89392.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>44696.50</td>\n",
       "      <td>0.58</td>\n",
       "      <td>4.60</td>\n",
       "      <td>4351.50</td>\n",
       "      <td>97952.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>25805.39</td>\n",
       "      <td>0.49</td>\n",
       "      <td>2.29</td>\n",
       "      <td>3262.36</td>\n",
       "      <td>90613.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>24828.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>22348.75</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>2406.00</td>\n",
       "      <td>52836.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>44696.50</td>\n",
       "      <td>1.00</td>\n",
       "      <td>5.00</td>\n",
       "      <td>4089.00</td>\n",
       "      <td>66396.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>67044.25</td>\n",
       "      <td>1.00</td>\n",
       "      <td>6.00</td>\n",
       "      <td>6094.00</td>\n",
       "      <td>103440.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>89392.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>8.00</td>\n",
       "      <td>31894.00</td>\n",
       "      <td>724068.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            id  marital_status  vintage  claim_amount      cltv\n",
       "count 89392.00        89392.00 89392.00      89392.00  89392.00\n",
       "mean  44696.50            0.58     4.60       4351.50  97952.83\n",
       "std   25805.39            0.49     2.29       3262.36  90613.81\n",
       "min       1.00            0.00     0.00          0.00  24828.00\n",
       "25%   22348.75            0.00     3.00       2406.00  52836.00\n",
       "50%   44696.50            1.00     5.00       4089.00  66396.00\n",
       "75%   67044.25            1.00     6.00       6094.00 103440.00\n",
       "max   89392.00            1.00     8.00      31894.00 724068.00"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d47fd9f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Male' 'Female']\n",
      "['Urban' 'Rural']\n",
      "['Bachelor' 'High School' 'Others']\n",
      "['5L-10L' 'More than 10L' '2L-5L' '<=2L']\n",
      "['More than 1' '1']\n",
      "['A' 'C' 'B']\n",
      "['Platinum' 'Gold' 'Silver']\n"
     ]
    }
   ],
   "source": [
    "categorical_variables = train.columns[train.dtypes == 'object']\n",
    "for i in categorical_variables:\n",
    "    print(train[i].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "3342fe56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# More EDA with sweetviz\n",
    "\n",
    "#eda = sv.analyze(train)\n",
    "#eda.show_html('edal.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3cefbb7",
   "metadata": {
    "id": "a3cefbb7"
   },
   "source": [
    "## Data Processsing and Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "4ed3cde4",
   "metadata": {
    "id": "4ed3cde4"
   },
   "outputs": [],
   "source": [
    "#Splitting x and y\n",
    "y_train = train['cltv']\n",
    "\n",
    "x_train = train.iloc[:,1:11]\n",
    "x_test = test.iloc[:,1:11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "2ba467da",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2ba467da",
    "outputId": "c6d36e25-3a86-456f-e92f-1bc65ed85a8b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(148987, 11)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Labelling Train and test to join them for easy analysis and to split them later for test and train seperately\n",
    "\n",
    "x_train['data'] = 'train'\n",
    "x_test['data'] = 'test'\n",
    "all = pd.concat([x_train,x_test])\n",
    "all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "3TqMlByG20zc",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3TqMlByG20zc",
    "outputId": "ce2a66c8-3278-4fd4-cd43-91bf61bd8a2a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        train\n",
       "1        train\n",
       "2        train\n",
       "3        train\n",
       "4        train\n",
       "         ...  \n",
       "59590     test\n",
       "59591     test\n",
       "59592     test\n",
       "59593     test\n",
       "59594     test\n",
       "Name: data, Length: 148987, dtype: object"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_col = all['data']\n",
    "all.drop('data', axis=1, inplace=True)\n",
    "data_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "9c5136f7",
   "metadata": {
    "id": "9c5136f7"
   },
   "outputs": [],
   "source": [
    "# Convert times of day to numeric encoded form\n",
    "all['income']=all['income'].replace({ '<=2L':1, '2L-5L':2,'5L-10L':3, 'More than 10L': 4})\n",
    "all['type_of_policy'] = all['type_of_policy'].replace({'Platinum': 3, 'Gold': 2, 'Silver': 1})\n",
    "all['gender'] = all['gender'].replace({'Male': 0, 'Female': 1})\n",
    "all['num_policies'] = all['num_policies'].replace({'1': 0, 'More than 1': 1})\n",
    "all['area'] = all['area'].replace({'Rural': 0,'Urban': 1})\n",
    "all = pd.get_dummies(all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "eRFDKIPZA4Sk",
   "metadata": {
    "id": "eRFDKIPZA4Sk"
   },
   "outputs": [],
   "source": [
    "# Creating new feature Claim amount with respect to income\n",
    "\n",
    "h = all['income']\n",
    "all['claim/income'] = all['claim_amount']/h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "TS2YrUy72Kbo",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 287
    },
    "id": "TS2YrUy72Kbo",
    "outputId": "0b10f9f4-1590-4350-8d6d-b45b14d62b17"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>area</th>\n",
       "      <th>income</th>\n",
       "      <th>marital_status</th>\n",
       "      <th>vintage</th>\n",
       "      <th>claim_amount</th>\n",
       "      <th>num_policies</th>\n",
       "      <th>type_of_policy</th>\n",
       "      <th>qualification_Bachelor</th>\n",
       "      <th>qualification_High School</th>\n",
       "      <th>qualification_Others</th>\n",
       "      <th>policy_A</th>\n",
       "      <th>policy_B</th>\n",
       "      <th>policy_C</th>\n",
       "      <th>claim/income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5790</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1930.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>5080</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1693.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>2599</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>866.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>3508</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>877.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   gender  area  income  marital_status  vintage  claim_amount  num_policies  \\\n",
       "0       0     1       3               1        5          5790             1   \n",
       "1       0     0       3               0        8          5080             1   \n",
       "2       0     1       3               1        8          2599             1   \n",
       "3       1     0       3               0        7             0             1   \n",
       "4       0     1       4               1        6          3508             1   \n",
       "\n",
       "   type_of_policy  qualification_Bachelor  qualification_High School  \\\n",
       "0               3                       1                          0   \n",
       "1               3                       0                          1   \n",
       "2               3                       1                          0   \n",
       "3               3                       0                          1   \n",
       "4               2                       0                          1   \n",
       "\n",
       "   qualification_Others  policy_A  policy_B  policy_C  claim/income  \n",
       "0                     0         1         0         0       1930.00  \n",
       "1                     0         1         0         0       1693.33  \n",
       "2                     0         1         0         0        866.33  \n",
       "3                     0         1         0         0          0.00  \n",
       "4                     0         1         0         0        877.00  "
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "669224c2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "669224c2",
    "outputId": "de10819b-eccf-471e-9f75-96db371891de"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([], dtype='object')"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_cols= all.columns[np.where(all.dtypes == object)[0]]\n",
    "num_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "ade85438",
   "metadata": {
    "id": "ade85438"
   },
   "outputs": [],
   "source": [
    "num_cols2= ['claim_amount', 'claim/year' ]\n",
    "\n",
    "def remove_outliers(data,num_cols):\n",
    "    for col in num_cols:\n",
    "        limit = (data[col].quantile(0.75) - data[col].quantile(0.25))*1.5\n",
    "        \n",
    "        high = data[col].quantile(0.75) + limit\n",
    "        low = data[col].quantile(0.25)- limit\n",
    "        \n",
    "        data[col] = np.where(\n",
    "            data[col] > high,\n",
    "            high,\n",
    "            np.where(\n",
    "                data[col] < low,\n",
    "                low,\n",
    "                data[col]))\n",
    "    return(data)\n",
    "\n",
    "all = remove_outliers(all,num_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "vnzHdqng3MVE",
   "metadata": {
    "id": "vnzHdqng3MVE"
   },
   "outputs": [],
   "source": [
    "all['data'] = data_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "793fbbf7",
   "metadata": {
    "id": "793fbbf7"
   },
   "outputs": [],
   "source": [
    "# Seperate Train, Test features\n",
    "x_train = all[all['data'] == 'train'] \n",
    "x_test = all[all['data'] == 'test']\n",
    "                                                                                          \n",
    "x_train = x_train.drop(['data'], axis=1)\n",
    "x_test = x_test.drop(['data'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "qsRD9S4x0veI",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qsRD9S4x0veI",
    "outputId": "4e16df4d-fbba-4573-aaa3-99b8cd72fcb9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gender                       0\n",
       "area                         0\n",
       "income                       0\n",
       "marital_status               0\n",
       "vintage                      0\n",
       "claim_amount                 0\n",
       "num_policies                 0\n",
       "type_of_policy               0\n",
       "qualification_Bachelor       0\n",
       "qualification_High School    0\n",
       "qualification_Others         0\n",
       "policy_A                     0\n",
       "policy_B                     0\n",
       "policy_C                     0\n",
       "claim/income                 0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13ac8470",
   "metadata": {
    "id": "13ac8470"
   },
   "source": [
    "# AutoML "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "85044169",
   "metadata": {
    "id": "85044169"
   },
   "outputs": [],
   "source": [
    "automl_log = AutoML() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "fbc2ce7f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fbc2ce7f",
    "outputId": "c627744e-a198-4624-9515-07675a0f9d7f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[flaml.automl.automl: 01-22 20:57:41] {2715} INFO - task = regression\n",
      "[flaml.automl.automl: 01-22 20:57:41] {2717} INFO - Data split method: uniform\n",
      "[flaml.automl.automl: 01-22 20:57:41] {2720} INFO - Evaluation method: holdout\n",
      "[flaml.automl.automl: 01-22 20:57:41] {2847} INFO - Minimizing error metric: 1-r2\n",
      "[flaml.automl.automl: 01-22 20:57:41] {2993} INFO - List of ML learners in AutoML Run: ['lgbm']\n",
      "[flaml.automl.automl: 01-22 20:57:41] {3322} INFO - iteration 0, current learner lgbm\n",
      "[flaml.automl.automl: 01-22 20:57:41] {3460} INFO - Estimated sufficient time budget=4425s. Estimated necessary time budget=4s.\n",
      "[flaml.automl.automl: 01-22 20:57:41] {3507} INFO -  at 0.3s,\testimator lgbm's best error=0.9208,\tbest estimator lgbm's best error=0.9208\n",
      "[flaml.automl.automl: 01-22 20:57:41] {3322} INFO - iteration 1, current learner lgbm\n",
      "[flaml.automl.automl: 01-22 20:57:41] {3507} INFO -  at 0.4s,\testimator lgbm's best error=0.9208,\tbest estimator lgbm's best error=0.9208\n",
      "[flaml.automl.automl: 01-22 20:57:41] {3322} INFO - iteration 2, current learner lgbm\n",
      "[flaml.automl.automl: 01-22 20:57:41] {3507} INFO -  at 0.4s,\testimator lgbm's best error=0.8695,\tbest estimator lgbm's best error=0.8695\n",
      "[flaml.automl.automl: 01-22 20:57:41] {3322} INFO - iteration 3, current learner lgbm\n",
      "[flaml.automl.automl: 01-22 20:57:41] {3507} INFO -  at 0.5s,\testimator lgbm's best error=0.8541,\tbest estimator lgbm's best error=0.8541\n",
      "[flaml.automl.automl: 01-22 20:57:41] {3322} INFO - iteration 4, current learner lgbm\n",
      "[flaml.automl.automl: 01-22 20:57:41] {3507} INFO -  at 0.5s,\testimator lgbm's best error=0.8541,\tbest estimator lgbm's best error=0.8541\n",
      "[flaml.automl.automl: 01-22 20:57:41] {3322} INFO - iteration 5, current learner lgbm\n",
      "[flaml.automl.automl: 01-22 20:57:42] {3507} INFO -  at 0.6s,\testimator lgbm's best error=0.8541,\tbest estimator lgbm's best error=0.8541\n",
      "[flaml.automl.automl: 01-22 20:57:42] {3322} INFO - iteration 6, current learner lgbm\n",
      "[flaml.automl.automl: 01-22 20:57:42] {3507} INFO -  at 0.7s,\testimator lgbm's best error=0.8513,\tbest estimator lgbm's best error=0.8513\n",
      "[flaml.automl.automl: 01-22 20:57:42] {3322} INFO - iteration 7, current learner lgbm\n",
      "[flaml.automl.automl: 01-22 20:57:42] {3507} INFO -  at 0.7s,\testimator lgbm's best error=0.8513,\tbest estimator lgbm's best error=0.8513\n",
      "[flaml.automl.automl: 01-22 20:57:42] {3322} INFO - iteration 8, current learner lgbm\n",
      "[flaml.automl.automl: 01-22 20:57:42] {3507} INFO -  at 0.9s,\testimator lgbm's best error=0.8513,\tbest estimator lgbm's best error=0.8513\n",
      "[flaml.automl.automl: 01-22 20:57:42] {3322} INFO - iteration 9, current learner lgbm\n",
      "[flaml.automl.automl: 01-22 20:57:42] {3507} INFO -  at 0.9s,\testimator lgbm's best error=0.8513,\tbest estimator lgbm's best error=0.8513\n",
      "[flaml.automl.automl: 01-22 20:57:42] {3322} INFO - iteration 10, current learner lgbm\n",
      "[flaml.automl.automl: 01-22 20:57:42] {3507} INFO -  at 1.1s,\testimator lgbm's best error=0.8513,\tbest estimator lgbm's best error=0.8513\n",
      "[flaml.automl.automl: 01-22 20:57:42] {3322} INFO - iteration 11, current learner lgbm\n",
      "[flaml.automl.automl: 01-22 20:57:42] {3507} INFO -  at 1.2s,\testimator lgbm's best error=0.8510,\tbest estimator lgbm's best error=0.8510\n",
      "[flaml.automl.automl: 01-22 20:57:42] {3322} INFO - iteration 12, current learner lgbm\n",
      "[flaml.automl.automl: 01-22 20:57:42] {3507} INFO -  at 1.4s,\testimator lgbm's best error=0.8510,\tbest estimator lgbm's best error=0.8510\n",
      "[flaml.automl.automl: 01-22 20:57:42] {3322} INFO - iteration 13, current learner lgbm\n",
      "[flaml.automl.automl: 01-22 20:57:42] {3507} INFO -  at 1.5s,\testimator lgbm's best error=0.8510,\tbest estimator lgbm's best error=0.8510\n",
      "[flaml.automl.automl: 01-22 20:57:42] {3322} INFO - iteration 14, current learner lgbm\n",
      "[flaml.automl.automl: 01-22 20:57:43] {3507} INFO -  at 1.7s,\testimator lgbm's best error=0.8507,\tbest estimator lgbm's best error=0.8507\n",
      "[flaml.automl.automl: 01-22 20:57:43] {3322} INFO - iteration 15, current learner lgbm\n",
      "[flaml.automl.automl: 01-22 20:57:43] {3507} INFO -  at 1.9s,\testimator lgbm's best error=0.8507,\tbest estimator lgbm's best error=0.8507\n",
      "[flaml.automl.automl: 01-22 20:57:43] {3322} INFO - iteration 16, current learner lgbm\n",
      "[flaml.automl.automl: 01-22 20:57:43] {3507} INFO -  at 2.1s,\testimator lgbm's best error=0.8507,\tbest estimator lgbm's best error=0.8507\n",
      "[flaml.automl.automl: 01-22 20:57:43] {3322} INFO - iteration 17, current learner lgbm\n",
      "[flaml.automl.automl: 01-22 20:57:43] {3507} INFO -  at 2.4s,\testimator lgbm's best error=0.8503,\tbest estimator lgbm's best error=0.8503\n",
      "[flaml.automl.automl: 01-22 20:57:43] {3322} INFO - iteration 18, current learner lgbm\n",
      "[flaml.automl.automl: 01-22 20:57:44] {3507} INFO -  at 2.6s,\testimator lgbm's best error=0.8503,\tbest estimator lgbm's best error=0.8503\n",
      "[flaml.automl.automl: 01-22 20:57:44] {3322} INFO - iteration 19, current learner lgbm\n",
      "[flaml.automl.automl: 01-22 20:57:44] {3507} INFO -  at 2.9s,\testimator lgbm's best error=0.8499,\tbest estimator lgbm's best error=0.8499\n",
      "[flaml.automl.automl: 01-22 20:57:44] {3322} INFO - iteration 20, current learner lgbm\n",
      "[flaml.automl.automl: 01-22 20:57:44] {3507} INFO -  at 3.1s,\testimator lgbm's best error=0.8499,\tbest estimator lgbm's best error=0.8499\n",
      "[flaml.automl.automl: 01-22 20:57:44] {3322} INFO - iteration 21, current learner lgbm\n",
      "[flaml.automl.automl: 01-22 20:57:45] {3507} INFO -  at 3.8s,\testimator lgbm's best error=0.8488,\tbest estimator lgbm's best error=0.8488\n",
      "[flaml.automl.automl: 01-22 20:57:45] {3322} INFO - iteration 22, current learner lgbm\n",
      "[flaml.automl.automl: 01-22 20:57:46] {3507} INFO -  at 5.0s,\testimator lgbm's best error=0.8488,\tbest estimator lgbm's best error=0.8488\n",
      "[flaml.automl.automl: 01-22 20:57:46] {3322} INFO - iteration 23, current learner lgbm\n",
      "[flaml.automl.automl: 01-22 20:57:46] {3507} INFO -  at 5.4s,\testimator lgbm's best error=0.8488,\tbest estimator lgbm's best error=0.8488\n",
      "[flaml.automl.automl: 01-22 20:57:46] {3322} INFO - iteration 24, current learner lgbm\n",
      "[flaml.automl.automl: 01-22 20:57:47] {3507} INFO -  at 6.1s,\testimator lgbm's best error=0.8488,\tbest estimator lgbm's best error=0.8488\n",
      "[flaml.automl.automl: 01-22 20:57:47] {3322} INFO - iteration 25, current learner lgbm\n",
      "[flaml.automl.automl: 01-22 20:57:48] {3507} INFO -  at 6.6s,\testimator lgbm's best error=0.8488,\tbest estimator lgbm's best error=0.8488\n",
      "[flaml.automl.automl: 01-22 20:57:48] {3322} INFO - iteration 26, current learner lgbm\n",
      "[flaml.automl.automl: 01-22 20:57:48] {3507} INFO -  at 7.1s,\testimator lgbm's best error=0.8488,\tbest estimator lgbm's best error=0.8488\n",
      "[flaml.automl.automl: 01-22 20:57:48] {3322} INFO - iteration 27, current learner lgbm\n",
      "[flaml.automl.automl: 01-22 20:57:49] {3507} INFO -  at 7.9s,\testimator lgbm's best error=0.8488,\tbest estimator lgbm's best error=0.8488\n",
      "[flaml.automl.automl: 01-22 20:57:49] {3322} INFO - iteration 28, current learner lgbm\n",
      "[flaml.automl.automl: 01-22 20:57:50] {3507} INFO -  at 9.3s,\testimator lgbm's best error=0.8488,\tbest estimator lgbm's best error=0.8488\n",
      "[flaml.automl.automl: 01-22 20:57:50] {3322} INFO - iteration 29, current learner lgbm\n",
      "[flaml.automl.automl: 01-22 20:57:51] {3507} INFO -  at 9.7s,\testimator lgbm's best error=0.8488,\tbest estimator lgbm's best error=0.8488\n",
      "[flaml.automl.automl: 01-22 20:57:51] {3322} INFO - iteration 30, current learner lgbm\n",
      "[flaml.automl.automl: 01-22 20:57:51] {3507} INFO -  at 10.2s,\testimator lgbm's best error=0.8488,\tbest estimator lgbm's best error=0.8488\n",
      "[flaml.automl.automl: 01-22 20:57:51] {3322} INFO - iteration 31, current learner lgbm\n",
      "[flaml.automl.automl: 01-22 20:57:52] {3507} INFO -  at 11.2s,\testimator lgbm's best error=0.8488,\tbest estimator lgbm's best error=0.8488\n",
      "[flaml.automl.automl: 01-22 20:57:52] {3322} INFO - iteration 32, current learner lgbm\n",
      "[flaml.automl.automl: 01-22 20:57:52] {3507} INFO -  at 11.6s,\testimator lgbm's best error=0.8488,\tbest estimator lgbm's best error=0.8488\n",
      "[flaml.automl.automl: 01-22 20:57:52] {3322} INFO - iteration 33, current learner lgbm\n",
      "[flaml.automl.automl: 01-22 20:57:54] {3507} INFO -  at 12.8s,\testimator lgbm's best error=0.8488,\tbest estimator lgbm's best error=0.8488\n",
      "[flaml.automl.automl: 01-22 20:57:54] {3322} INFO - iteration 34, current learner lgbm\n",
      "[flaml.automl.automl: 01-22 20:57:54] {3507} INFO -  at 13.3s,\testimator lgbm's best error=0.8488,\tbest estimator lgbm's best error=0.8488\n",
      "[flaml.automl.automl: 01-22 20:57:54] {3322} INFO - iteration 35, current learner lgbm\n",
      "[flaml.automl.automl: 01-22 20:57:55] {3507} INFO -  at 14.3s,\testimator lgbm's best error=0.8488,\tbest estimator lgbm's best error=0.8488\n",
      "[flaml.automl.automl: 01-22 20:57:55] {3322} INFO - iteration 36, current learner lgbm\n",
      "[flaml.automl.automl: 01-22 20:57:58] {3507} INFO -  at 17.3s,\testimator lgbm's best error=0.8488,\tbest estimator lgbm's best error=0.8488\n",
      "[flaml.automl.automl: 01-22 20:57:58] {3322} INFO - iteration 37, current learner lgbm\n",
      "[flaml.automl.automl: 01-22 20:57:58] {3507} INFO -  at 17.5s,\testimator lgbm's best error=0.8488,\tbest estimator lgbm's best error=0.8488\n",
      "[flaml.automl.automl: 01-22 20:57:58] {3322} INFO - iteration 38, current learner lgbm\n",
      "[flaml.automl.automl: 01-22 20:58:00] {3507} INFO -  at 19.0s,\testimator lgbm's best error=0.8488,\tbest estimator lgbm's best error=0.8488\n",
      "[flaml.automl.automl: 01-22 20:58:00] {3322} INFO - iteration 39, current learner lgbm\n",
      "[flaml.automl.automl: 01-22 20:58:00] {3507} INFO -  at 19.4s,\testimator lgbm's best error=0.8488,\tbest estimator lgbm's best error=0.8488\n",
      "[flaml.automl.automl: 01-22 20:58:00] {3322} INFO - iteration 40, current learner lgbm\n",
      "[flaml.automl.automl: 01-22 20:58:02] {3507} INFO -  at 21.4s,\testimator lgbm's best error=0.8488,\tbest estimator lgbm's best error=0.8488\n",
      "[flaml.automl.automl: 01-22 20:58:02] {3322} INFO - iteration 41, current learner lgbm\n",
      "[flaml.automl.automl: 01-22 20:58:03] {3507} INFO -  at 21.7s,\testimator lgbm's best error=0.8488,\tbest estimator lgbm's best error=0.8488\n",
      "[flaml.automl.automl: 01-22 20:58:03] {3322} INFO - iteration 42, current learner lgbm\n",
      "[flaml.automl.automl: 01-22 20:58:03] {3507} INFO -  at 22.0s,\testimator lgbm's best error=0.8488,\tbest estimator lgbm's best error=0.8488\n",
      "[flaml.automl.automl: 01-22 20:58:03] {3322} INFO - iteration 43, current learner lgbm\n",
      "[flaml.automl.automl: 01-22 20:58:05] {3507} INFO -  at 24.6s,\testimator lgbm's best error=0.8488,\tbest estimator lgbm's best error=0.8488\n",
      "[flaml.automl.automl: 01-22 20:58:05] {3322} INFO - iteration 44, current learner lgbm\n",
      "[flaml.automl.automl: 01-22 20:58:07] {3507} INFO -  at 25.7s,\testimator lgbm's best error=0.8488,\tbest estimator lgbm's best error=0.8488\n",
      "[flaml.automl.automl: 01-22 20:58:07] {3322} INFO - iteration 45, current learner lgbm\n",
      "[flaml.automl.automl: 01-22 20:58:07] {3507} INFO -  at 26.0s,\testimator lgbm's best error=0.8488,\tbest estimator lgbm's best error=0.8488\n",
      "[flaml.automl.automl: 01-22 20:58:07] {3322} INFO - iteration 46, current learner lgbm\n",
      "[flaml.automl.automl: 01-22 20:58:07] {3507} INFO -  at 26.3s,\testimator lgbm's best error=0.8488,\tbest estimator lgbm's best error=0.8488\n",
      "[flaml.automl.automl: 01-22 20:58:07] {3322} INFO - iteration 47, current learner lgbm\n",
      "[flaml.automl.automl: 01-22 20:58:09] {3507} INFO -  at 28.5s,\testimator lgbm's best error=0.8488,\tbest estimator lgbm's best error=0.8488\n",
      "[flaml.automl.automl: 01-22 20:58:09] {3322} INFO - iteration 48, current learner lgbm\n",
      "[flaml.automl.automl: 01-22 20:58:10] {3507} INFO -  at 28.7s,\testimator lgbm's best error=0.8488,\tbest estimator lgbm's best error=0.8488\n",
      "[flaml.automl.automl: 01-22 20:58:10] {3322} INFO - iteration 49, current learner lgbm\n",
      "[flaml.automl.automl: 01-22 20:58:13] {3507} INFO -  at 32.6s,\testimator lgbm's best error=0.8488,\tbest estimator lgbm's best error=0.8488\n",
      "[flaml.automl.automl: 01-22 20:58:13] {3322} INFO - iteration 50, current learner lgbm\n",
      "[flaml.automl.automl: 01-22 20:58:14] {3507} INFO -  at 32.8s,\testimator lgbm's best error=0.8488,\tbest estimator lgbm's best error=0.8488\n",
      "[flaml.automl.automl: 01-22 20:58:14] {3322} INFO - iteration 51, current learner lgbm\n",
      "[flaml.automl.automl: 01-22 20:58:18] {3507} INFO -  at 37.4s,\testimator lgbm's best error=0.8488,\tbest estimator lgbm's best error=0.8488\n",
      "[flaml.automl.automl: 01-22 20:58:18] {3322} INFO - iteration 52, current learner lgbm\n",
      "[flaml.automl.automl: 01-22 20:58:23] {3507} INFO -  at 42.2s,\testimator lgbm's best error=0.8488,\tbest estimator lgbm's best error=0.8488\n",
      "[flaml.automl.automl: 01-22 20:58:23] {3322} INFO - iteration 53, current learner lgbm\n",
      "[flaml.automl.automl: 01-22 20:58:23] {3507} INFO -  at 42.4s,\testimator lgbm's best error=0.8488,\tbest estimator lgbm's best error=0.8488\n",
      "[flaml.automl.automl: 01-22 20:58:23] {3322} INFO - iteration 54, current learner lgbm\n",
      "[flaml.automl.automl: 01-22 20:58:27] {3507} INFO -  at 45.7s,\testimator lgbm's best error=0.8488,\tbest estimator lgbm's best error=0.8488\n",
      "[flaml.automl.automl: 01-22 20:58:27] {3322} INFO - iteration 55, current learner lgbm\n",
      "[flaml.automl.automl: 01-22 20:58:27] {3507} INFO -  at 45.9s,\testimator lgbm's best error=0.8488,\tbest estimator lgbm's best error=0.8488\n",
      "[flaml.automl.automl: 01-22 20:58:27] {3322} INFO - iteration 56, current learner lgbm\n",
      "[flaml.automl.automl: 01-22 20:58:29] {3507} INFO -  at 47.7s,\testimator lgbm's best error=0.8488,\tbest estimator lgbm's best error=0.8488\n",
      "[flaml.automl.automl: 01-22 20:58:29] {3322} INFO - iteration 57, current learner lgbm\n",
      "[flaml.automl.automl: 01-22 20:58:29] {3507} INFO -  at 48.1s,\testimator lgbm's best error=0.8488,\tbest estimator lgbm's best error=0.8488\n",
      "[flaml.automl.automl: 01-22 20:58:29] {3322} INFO - iteration 58, current learner lgbm\n",
      "[flaml.automl.automl: 01-22 20:58:30] {3507} INFO -  at 48.6s,\testimator lgbm's best error=0.8488,\tbest estimator lgbm's best error=0.8488\n",
      "[flaml.automl.automl: 01-22 20:58:30] {3322} INFO - iteration 59, current learner lgbm\n",
      "[flaml.automl.automl: 01-22 20:58:30] {3507} INFO -  at 49.5s,\testimator lgbm's best error=0.8488,\tbest estimator lgbm's best error=0.8488\n",
      "[flaml.automl.automl: 01-22 20:58:30] {3322} INFO - iteration 60, current learner lgbm\n",
      "[flaml.automl.automl: 01-22 20:58:31] {3507} INFO -  at 49.9s,\testimator lgbm's best error=0.8488,\tbest estimator lgbm's best error=0.8488\n",
      "[flaml.automl.automl: 01-22 20:58:31] {3322} INFO - iteration 61, current learner lgbm\n",
      "[flaml.automl.automl: 01-22 20:58:32] {3507} INFO -  at 51.3s,\testimator lgbm's best error=0.8488,\tbest estimator lgbm's best error=0.8488\n",
      "[flaml.automl.automl: 01-22 20:58:32] {3322} INFO - iteration 62, current learner lgbm\n",
      "[flaml.automl.automl: 01-22 20:58:36] {3507} INFO -  at 54.9s,\testimator lgbm's best error=0.8488,\tbest estimator lgbm's best error=0.8488\n",
      "[flaml.automl.automl: 01-22 20:58:36] {3322} INFO - iteration 63, current learner lgbm\n",
      "[flaml.automl.automl: 01-22 20:58:36] {3507} INFO -  at 55.2s,\testimator lgbm's best error=0.8488,\tbest estimator lgbm's best error=0.8488\n",
      "[flaml.automl.automl: 01-22 20:58:36] {3322} INFO - iteration 64, current learner lgbm\n",
      "[flaml.automl.automl: 01-22 20:58:37] {3507} INFO -  at 56.1s,\testimator lgbm's best error=0.8488,\tbest estimator lgbm's best error=0.8488\n",
      "[flaml.automl.automl: 01-22 20:58:37] {3322} INFO - iteration 65, current learner lgbm\n",
      "[flaml.automl.automl: 01-22 20:58:38] {3507} INFO -  at 56.7s,\testimator lgbm's best error=0.8488,\tbest estimator lgbm's best error=0.8488\n",
      "[flaml.automl.automl: 01-22 20:58:38] {3322} INFO - iteration 66, current learner lgbm\n",
      "[flaml.automl.automl: 01-22 20:58:39] {3507} INFO -  at 57.9s,\testimator lgbm's best error=0.8488,\tbest estimator lgbm's best error=0.8488\n",
      "[flaml.automl.automl: 01-22 20:58:39] {3322} INFO - iteration 67, current learner lgbm\n",
      "[flaml.automl.automl: 01-22 20:58:39] {3507} INFO -  at 58.5s,\testimator lgbm's best error=0.8488,\tbest estimator lgbm's best error=0.8488\n",
      "[flaml.automl.automl: 01-22 20:58:39] {3322} INFO - iteration 68, current learner lgbm\n",
      "[flaml.automl.automl: 01-22 20:58:40] {3507} INFO -  at 59.0s,\testimator lgbm's best error=0.8488,\tbest estimator lgbm's best error=0.8488\n",
      "[flaml.automl.automl: 01-22 20:58:40] {3322} INFO - iteration 69, current learner lgbm\n",
      "[flaml.automl.automl: 01-22 20:58:41] {3507} INFO -  at 60.0s,\testimator lgbm's best error=0.8488,\tbest estimator lgbm's best error=0.8488\n",
      "[flaml.automl.automl: 01-22 20:58:41] {3771} INFO - retrain lgbm for 0.6s\n",
      "[flaml.automl.automl: 01-22 20:58:41] {3778} INFO - retrained model: LGBMRegressor(colsample_bytree=0.6839995423902253,\n",
      "              learning_rate=0.0931069218713331, max_bin=63,\n",
      "              min_child_samples=18, n_estimators=74, num_leaves=9,\n",
      "              reg_alpha=0.002062299388929132, reg_lambda=67.29136614766921,\n",
      "              verbose=-1)\n",
      "[flaml.automl.automl: 01-22 20:58:41] {3023} INFO - fit succeeded\n",
      "[flaml.automl.automl: 01-22 20:58:41] {3024} INFO - Time taken to find the best model: 3.7982187271118164\n"
     ]
    }
   ],
   "source": [
    "automl_log.fit(x_train, y_train, task=\"regression\",metric='r2',time_budget=60,estimator_list = ['lgbm'],\n",
    "          n_splits=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nJJSwFweD-n7",
   "metadata": {
    "id": "nJJSwFweD-n7"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "ddf548bb",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ddf548bb",
    "outputId": "1218998e-ac49-41f8-a29f-43120c795d40"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best r2 on validation data: 0.1512\n"
     ]
    }
   ],
   "source": [
    "print('Best r2 on validation data: {0:.4g}'.format(1-automl_log.best_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "7a345d13",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 408
    },
    "id": "7a345d13",
    "outputId": "62e7dc98-5e7b-4e97-de5f-6d02bb1746a3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Feature Importance')"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "feature_importance = automl_log.feature_importances_\n",
    "sorted_idx = np.argsort(feature_importance)[-25:]\n",
    "\n",
    "fig = plt.figure(figsize=(12, 6))\n",
    "plt.barh(range(len(sorted_idx)), feature_importance[sorted_idx], align='center')\n",
    "plt.yticks(range(len(sorted_idx)), np.array(x_train.columns)[sorted_idx])\n",
    "plt.title('Feature Importance')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e111497",
   "metadata": {},
   "source": [
    "# Converting to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "id": "5f4499f9",
   "metadata": {
    "id": "5f4499f9"
   },
   "outputs": [],
   "source": [
    "ss['cltv'] = automl_log.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "id": "5092e9a8",
   "metadata": {
    "id": "5092e9a8"
   },
   "outputs": [],
   "source": [
    "ss.to_csv('predict.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "d3744011",
   "metadata": {
    "id": "d3744011"
   },
   "outputs": [],
   "source": [
    "ss = pd.read_csv(\"drive/MyDrive/Competition/sample_submission.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fca71bc9",
   "metadata": {},
   "source": [
    "# LazyPredict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ApbujiMy6mJU",
   "metadata": {
    "id": "ApbujiMy6mJU"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 11/42 [00:26<01:42,  3.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GaussianProcessRegressor model failed to execute\n",
      "Unable to allocate 38.1 GiB for an array with shape (71513, 71513) and data type float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 17/42 [00:40<00:51,  2.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KernelRidge model failed to execute\n",
      "Unable to allocate 38.1 GiB for an array with shape (71513, 71513) and data type float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 26/42 [00:50<00:33,  2.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLPRegressor model failed to execute\n",
      "underflow encountered in true_divide\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▍  | 31/42 [09:38<08:36, 46.97s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QuantileRegressor model failed to execute\n",
      "Unable to allocate 38.1 GiB for an array with shape (71513, 71513) and data type float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 42/42 [18:59<00:00, 27.13s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                               Adjusted R-Squared  R-Squared      RMSE  \\\n",
      "Model                                                                    \n",
      "GradientBoostingRegressor                    0.16       0.16  82021.59   \n",
      "HistGradientBoostingRegressor                0.16       0.16  82082.32   \n",
      "LGBMRegressor                                0.16       0.16  82157.73   \n",
      "PoissonRegressor                             0.16       0.16  82171.28   \n",
      "LassoLars                                    0.15       0.15  82402.33   \n",
      "LassoCV                                      0.15       0.15  82413.22   \n",
      "Lasso                                        0.15       0.15  82415.19   \n",
      "LassoLarsIC                                  0.15       0.15  82415.25   \n",
      "LarsCV                                       0.15       0.15  82415.25   \n",
      "Lars                                         0.15       0.15  82415.25   \n",
      "LassoLarsCV                                  0.15       0.15  82415.25   \n",
      "Ridge                                        0.15       0.15  82415.26   \n",
      "RidgeCV                                      0.15       0.15  82415.29   \n",
      "BayesianRidge                                0.15       0.15  82415.55   \n",
      "LinearRegression                             0.15       0.15  82415.95   \n",
      "TransformedTargetRegressor                   0.15       0.15  82415.95   \n",
      "OrthogonalMatchingPursuitCV                  0.15       0.15  82473.48   \n",
      "SGDRegressor                                 0.15       0.15  82486.49   \n",
      "ElasticNet                                   0.14       0.14  83060.42   \n",
      "XGBRegressor                                 0.13       0.13  83220.38   \n",
      "OrthogonalMatchingPursuit                    0.13       0.13  83248.91   \n",
      "GammaRegressor                               0.12       0.12  83767.44   \n",
      "TweedieRegressor                             0.12       0.12  83867.05   \n",
      "HuberRegressor                               0.05       0.05  87127.40   \n",
      "PassiveAggressiveRegressor                   0.03       0.03  88082.90   \n",
      "RandomForestRegressor                        0.03       0.03  88150.22   \n",
      "AdaBoostRegressor                            0.01       0.01  88858.90   \n",
      "ElasticNetCV                                 0.01       0.01  88880.72   \n",
      "DummyRegressor                              -0.00      -0.00  89461.35   \n",
      "KNeighborsRegressor                         -0.00      -0.00  89544.99   \n",
      "NuSVR                                       -0.04      -0.04  91047.52   \n",
      "BaggingRegressor                            -0.05      -0.05  91504.11   \n",
      "RANSACRegressor                             -0.10      -0.10  93658.68   \n",
      "SVR                                         -0.11      -0.11  94231.13   \n",
      "ExtraTreesRegressor                         -0.14      -0.14  95655.16   \n",
      "LinearSVR                                   -0.20      -0.19  97770.57   \n",
      "ExtraTreeRegressor                          -0.71      -0.71 116833.40   \n",
      "DecisionTreeRegressor                       -0.75      -0.75 118410.86   \n",
      "\n",
      "                               Time Taken  \n",
      "Model                                      \n",
      "GradientBoostingRegressor            6.38  \n",
      "HistGradientBoostingRegressor        0.47  \n",
      "LGBMRegressor                        0.64  \n",
      "PoissonRegressor                     0.11  \n",
      "LassoLars                            0.10  \n",
      "LassoCV                              0.78  \n",
      "Lasso                                1.34  \n",
      "LassoLarsIC                          0.16  \n",
      "LarsCV                               0.39  \n",
      "Lars                                 0.10  \n",
      "LassoLarsCV                          0.37  \n",
      "Ridge                                0.09  \n",
      "RidgeCV                              0.14  \n",
      "BayesianRidge                        0.15  \n",
      "LinearRegression                     0.11  \n",
      "TransformedTargetRegressor           0.14  \n",
      "OrthogonalMatchingPursuitCV          0.27  \n",
      "SGDRegressor                         0.28  \n",
      "ElasticNet                           0.12  \n",
      "XGBRegressor                         4.34  \n",
      "OrthogonalMatchingPursuit            0.09  \n",
      "GammaRegressor                       0.09  \n",
      "TweedieRegressor                     0.12  \n",
      "HuberRegressor                       0.40  \n",
      "PassiveAggressiveRegressor           0.25  \n",
      "RandomForestRegressor               29.00  \n",
      "AdaBoostRegressor                    2.00  \n",
      "ElasticNetCV                         0.67  \n",
      "DummyRegressor                       0.09  \n",
      "KNeighborsRegressor                  6.83  \n",
      "NuSVR                              526.97  \n",
      "BaggingRegressor                     2.97  \n",
      "RANSACRegressor                      0.48  \n",
      "SVR                                525.95  \n",
      "ExtraTreesRegressor                 19.43  \n",
      "LinearSVR                            0.15  \n",
      "ExtraTreeRegressor                   0.28  \n",
      "DecisionTreeRegressor                0.54  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#This takes lot of time to run\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(x_train, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "reg = LazyRegressor(verbose=0, ignore_warnings=False, custom_metric=None)\n",
    "models, predictions = reg.fit(X_train, X_test, y_train, y_test)\n",
    "\n",
    "print(models)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61f4880b",
   "metadata": {},
   "source": [
    "Tried XGBoost, LGBM using AutoML\n",
    "Tried Lazy Predict and GradientBoostingRegressor had the highest r2_score\n",
    "\n",
    "Uploaded both to get the results for Private Data\n",
    "LGBM performed well with High accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cad323b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
